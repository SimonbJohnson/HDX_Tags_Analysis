{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdx.utilities.easy_logging import setup_logging\n",
    "from hdx.hdx_configuration import Configuration\n",
    "from hdx.data.dataset import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy import spatial\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from hdx.data.resource import Resource\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "import gensim\n",
    "import os;\n",
    "import re \n",
    "import pandas as pd\n",
    "import re;\n",
    "import logging;\n",
    "import sqlite3;\n",
    "import time;\n",
    "import sys;\n",
    "import multiprocessing;\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt;\n",
    "from itertools import cycle;\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define important paramters:\n",
    "Num_of_words = 20 ## 15, 20 , 30\n",
    "max_DF =0.90 ## 0.85 , 0.95\n",
    "k = 4 # the extra tags returned by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extraction (TF-IDF),  Tag expansion, distance computing, and scoring similar tags for the datasets.\n",
    "<ol>\n",
    "<li> Read the preprocessed content </li>\n",
    "<li> Generate tf-idf for the document (keywords extraction) </li>\n",
    "<li> Expand tags by word2vec model </li>\n",
    "<li> Represent the keyword of the dataset by word2vec model </li>\n",
    "<li> Represent HDX tags by word2vec model </li>\n",
    "<li> Compute the similarity between the HDX tags vs dataset </li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the preprocessed content:\n",
    "# a list of datasets and their metadata\n",
    "df=pd.read_csv(\"after_clean_v3.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'notes', 'tags', 'header', 'organization', 'dataset_source',\n",
       "       'geodata', 'country', 'tag_list', 'doc', 'All_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do cleaning for the header if it was not done\n",
    "df['header'] = Utility.data_clean(df,['header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the content of all metadata fields into raw text\n",
    "def get_all_text(df):\n",
    "    #df.tags.astype(str)+ \" \" +\n",
    "    textdata =  df.title.fillna('').astype(str)+\" \" + df.header.fillna('').astype(str) +\" \" + df.organization.fillna('').astype(str) +\" \" +  df.notes.fillna('').astype(str)+\" \"+ df.country.fillna('').astype(str) + \" \" + df.geodata.fillna('').astype(str) \n",
    "    return textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the stop words list in addition standard english stopwrds\n",
    "stoplist= set(stopwords.words('english'))\n",
    "stoplist.update(['type','etc','also','whole','this','can','be','unnamed','nan','file','xls','xlsx','etc','zip','link',\n",
    "                 'description','https','of','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the text of all metadata fields\n",
    "df['All_text'] =  get_all_text (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stopwords \n",
    "df['text']=  Utility.remove_stopwords(df['All_text'],stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2131)\t1\n",
      "  (0, 620)\t1\n",
      "  (0, 1058)\t1\n",
      "  (0, 743)\t1\n",
      "  (0, 2312)\t1\n",
      "  (0, 1167)\t1\n",
      "  (0, 1000)\t1\n",
      "  (0, 2363)\t1\n",
      "  (0, 1592)\t1\n",
      "  (0, 1066)\t1\n",
      "  (0, 385)\t1\n",
      "  (0, 256)\t1\n",
      "  (0, 2392)\t1\n",
      "  (0, 2110)\t1\n",
      "  (0, 1540)\t1\n",
      "  (0, 2372)\t1\n",
      "  (0, 985)\t1\n",
      "  (0, 1183)\t1\n",
      "  (0, 2233)\t1\n",
      "  (0, 2253)\t1\n",
      "  (0, 1705)\t1\n",
      "  (0, 388)\t1\n",
      "  (0, 2142)\t1\n",
      "  (0, 1385)\t1\n",
      "  (0, 1369)\t1\n",
      "  :\t:\n",
      "  (611, 2048)\t1\n",
      "  (611, 511)\t1\n",
      "  (611, 2344)\t1\n",
      "  (611, 2069)\t1\n",
      "  (611, 924)\t1\n",
      "  (611, 2050)\t1\n",
      "  (611, 521)\t1\n",
      "  (611, 224)\t1\n",
      "  (611, 2231)\t1\n",
      "  (611, 1512)\t1\n",
      "  (611, 1097)\t1\n",
      "  (611, 853)\t1\n",
      "  (611, 621)\t1\n",
      "  (611, 425)\t1\n",
      "  (611, 410)\t1\n",
      "  (611, 354)\t1\n",
      "  (611, 1516)\t1\n",
      "  (611, 865)\t1\n",
      "  (611, 343)\t1\n",
      "  (611, 2065)\t1\n",
      "  (611, 2156)\t1\n",
      "  (611, 1517)\t1\n",
      "  (611, 1744)\t1\n",
      "  (611, 1059)\t1\n",
      "  (611, 692)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "# load a set of stop words\n",
    "# Get the text column\n",
    "# Ignore words that appear in 85% of documents\n",
    "# Eliminate stop words </li> \n",
    "docs=df['All_text'].tolist()\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stoplist,binary=True)#, ngram_range =(1,2))\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "print(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term frequncy inverse document frequncy transformer  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=False)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.base.BaseEstimator.get_params(self, deep=True)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfTransformer.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['somalia', 'demographic', 'health']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##quick look at top words\n",
    "list(cv.vocabulary_.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mapping of index to word name\n",
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Doc=====\n",
      " current tags  demographics education indicators socioeconomics sustainable development\n",
      "\n",
      "===Keywords===\n",
      "world 0.11\n",
      "women 0.11\n",
      "wider 0.11\n",
      "venezuela 0.11\n",
      "various 0.11\n",
      "unesco 0.11\n",
      "today 0.11\n",
      "ties 0.11\n",
      "sustainable 0.11\n",
      "strengthens 0.11\n",
      "specialized 0.11\n",
      "socioeconomic 0.11\n",
      "societies 0.11\n",
      "serves 0.11\n",
      "serve 0.11\n"
     ]
    }
   ],
   "source": [
    "## use this as a test to see the top words in the docuemnt\n",
    "# get the document that we want to extract keywords from\n",
    "doc=df['All_text'].ix[100]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc])) #tfidf_transformer\n",
    " \n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=Utility.sort_coo(tf_idf_vector.tocoo())\n",
    " \n",
    "#extract only the top n; n here is 15\n",
    "keywords=Utility.extract_topn_from_vector(feature_names,sorted_items,15)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\n=====Doc=====\")\n",
    "#print(doc)\n",
    "print(\" current tags \" , df['tags'].ix[100])\n",
    "\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the document that we want to extract keywords from.\n",
    "#generate tf-idf for the given document.\n",
    "# sort the tf-idf vectors by descending order of scores.\n",
    "#extract only the top n; n here is 10\n",
    "\n",
    "tfidf_vecs = []\n",
    "df['tfidf'] =\" \"\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    doc=df['All_text'].ix[i]\n",
    "    candidates=\"\"\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc])) #tfidf_transformer.transform(\n",
    "    sorted_items=Utility.sort_coo(tf_idf_vector.tocoo()) \n",
    "    keywords=Utility.extract_topn_from_vector(feature_names,sorted_items,Num_of_words)\n",
    "    vec =np.array(list(keywords.values()))\n",
    "    for k in keywords: \n",
    "        candidates+=k +\" \"\n",
    "    tfidf_vecs.append(vec)\n",
    "    df.ix[i]['tfidf'] = candidates  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ghana education indicators uneca ghana education indicators uneca united nations economic commission africa created title united nations economic commission africa uneca organization true state active image url revision id fb c e ce e c b aa c organization aa ae cf c c e approval status approved dataset contains many indicators education enrolment rate primary education ratio girls boys primary education list find ghana'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].ix[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'united uneca ratio rate primary nations many list indicators girls ghana find fb enrolment education economic dataset contains commission cf '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tfidf'].ix[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google pretrained word2vec model:\n",
    "model, word = Utility.get_model()\n",
    "index2word_set = set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the list of HDX valid tags\n",
    "tag_list_clean = Utility.read_concept_tags()\n",
    "len(tag_list_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do tag expansion using word2vec simialr words\n",
    "new_tag_list_clean = []\n",
    "for tag in tag_list_clean:\n",
    "    expanded = Utility.expan_tags(tag, model , 5)\n",
    "    if expanded ==\"\":\n",
    "        new_tag_list_clean.append(tag)\n",
    "    else:\n",
    "        new_tag_list_clean.append(expanded+\" \"+tag)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title  \\\n",
      "578                   secondary education school rates   \n",
      "22                   gambia education indicators uneca   \n",
      "199  liechtenstein sustainable development educatio...   \n",
      "423  jordan demographic health education transport ...   \n",
      "327              cabo verde education indicators uneca   \n",
      "..                                                 ...   \n",
      "512                uganda number girls enrolled school   \n",
      "126  south sudan sustainable development education ...   \n",
      "413  malawi demographic health education transport ...   \n",
      "4                              hotosm dominica schools   \n",
      "356  turkmenistan demographic health education tran...   \n",
      "\n",
      "                                                 notes  \\\n",
      "578  secondary education school rates including bre...   \n",
      "22   this dataset contains many indicators educatio...   \n",
      "199  contains data from unesco data portal covering...   \n",
      "423  urban indicators data available here analyzed ...   \n",
      "327  this dataset contains many indicators educatio...   \n",
      "..                                                 ...   \n",
      "512  this data about access girls basic education a...   \n",
      "126  contains data from unesco data portal covering...   \n",
      "413  urban indicators data available here analyzed ...   \n",
      "4    openstreetmap exports applications this theme ...   \n",
      "356  urban indicators data available here analyzed ...   \n",
      "\n",
      "                                                  tags  \\\n",
      "578                   child education school secondary   \n",
      "22                                           education   \n",
      "199  demographics education indicators socioeconomi...   \n",
      "423              education health population transport   \n",
      "327                                          education   \n",
      "..                                                 ...   \n",
      "512  africa data nairobi data devtrac east africa e...   \n",
      "126  demographics education indicators socioeconomi...   \n",
      "413              education health population transport   \n",
      "4             dominica education openstreetmap schools   \n",
      "356              education health population transport   \n",
      "\n",
      "                                                header  \\\n",
      "578                   secondary education school rates   \n",
      "22                   gambia education indicators uneca   \n",
      "199  liechtenstein sustainable development educatio...   \n",
      "423  jordan demographic health education transport ...   \n",
      "327              cabo verde education indicators uneca   \n",
      "..                                                 ...   \n",
      "512                uganda number girls enrolled school   \n",
      "126  south sudan sustainable development education ...   \n",
      "413  malawi demographic health education transport ...   \n",
      "4                              hotosm dominica schools   \n",
      "356  turkmenistan demographic health education tran...   \n",
      "\n",
      "                                          organization  \\\n",
      "578  description unicef works countries territories...   \n",
      "22   description united nations economic commission...   \n",
      "199  description unesco specialized agency responsi...   \n",
      "423  description global urban observatory helps cit...   \n",
      "327  description united nations economic commission...   \n",
      "..                                                 ...   \n",
      "512  description openafrica aims largest independen...   \n",
      "126  description unesco specialized agency responsi...   \n",
      "413  description global urban observatory helps cit...   \n",
      "4    description ocha regional office latin america...   \n",
      "356  description global urban observatory helps cit...   \n",
      "\n",
      "                  dataset_source  geodata        country  \\\n",
      "578        unicef data analytics      NaN          world   \n",
      "22                         uneca      NaN         gambia   \n",
      "199  unesco institute statistics      NaN  liechtenstein   \n",
      "423                    unhabitat      NaN         jordan   \n",
      "327                        uneca      NaN     cabo verde   \n",
      "..                           ...      ...            ...   \n",
      "512                unicef uganda      NaN         uganda   \n",
      "126  unesco institute statistics      NaN    south sudan   \n",
      "413                    unhabitat      NaN         malawi   \n",
      "4     openstreetmap contributors  geodata       dominica   \n",
      "356                    unhabitat      NaN   turkmenistan   \n",
      "\n",
      "                                              tag_list  \\\n",
      "578  ['child', 'education', 'out-of-school', 'secon...   \n",
      "22                                       ['education']   \n",
      "199  ['demographics', 'education', 'indicators', 's...   \n",
      "423  ['education', 'health', 'hxl', 'population', '...   \n",
      "327                                      ['education']   \n",
      "..                                                 ...   \n",
      "512  ['africa', 'data lab nairobi', 'data-ug', 'dev...   \n",
      "126  ['demographics', 'education', 'indicators', 's...   \n",
      "413  ['education', 'health', 'hxl', 'population', '...   \n",
      "4    ['dominica', 'education', 'openstreetmap', 'os...   \n",
      "356  ['education', 'health', 'hxl', 'population', '...   \n",
      "\n",
      "                                                   doc  \\\n",
      "578  secondary education school rates unnamed unnam...   \n",
      "22   gambia education indicators uneca indicator de...   \n",
      "199  liechtenstein sustainable development educatio...   \n",
      "423  jordan demographic health education transport ...   \n",
      "327  cabo verde education indicators uneca indicato...   \n",
      "..                                                 ...   \n",
      "512  uganda number girls enrolled school head title...   \n",
      "126  south sudan sustainable development education ...   \n",
      "413  malawi demographic health education transport ...   \n",
      "4    hotosm dominica schools  description ocha regi...   \n",
      "356  turkmenistan demographic health education tran...   \n",
      "\n",
      "                                              All_text  \\\n",
      "578  secondary education school rates secondary edu...   \n",
      "22   gambia education indicators uneca gambia educa...   \n",
      "199  liechtenstein sustainable development educatio...   \n",
      "423  jordan demographic health education transport ...   \n",
      "327  cabo verde education indicators uneca cabo ver...   \n",
      "..                                                 ...   \n",
      "512  uganda number girls enrolled school uganda num...   \n",
      "126  south sudan sustainable development education ...   \n",
      "413  malawi demographic health education transport ...   \n",
      "4    hotosm dominica schools hotosm dominica school...   \n",
      "356  turkmenistan demographic health education tran...   \n",
      "\n",
      "                                                  text  \\\n",
      "578  secondary education school rates secondary edu...   \n",
      "22   gambia education indicators uneca gambia educa...   \n",
      "199  liechtenstein sustainable development educatio...   \n",
      "423  jordan demographic health education transport ...   \n",
      "327  cabo verde education indicators uneca cabo ver...   \n",
      "..                                                 ...   \n",
      "512  uganda number girls enrolled school uganda num...   \n",
      "126  south sudan sustainable development education ...   \n",
      "413  malawi demographic health education transport ...   \n",
      "4    hotosm dominica schools hotosm dominica school...   \n",
      "356  turkmenistan demographic health education tran...   \n",
      "\n",
      "                                                 tfidf  \n",
      "578  world works unicef territories standard second...  \n",
      "22   united uneca ratio rate primary nations many l...  \n",
      "199  world women wider various unesco today ties su...  \n",
      "423  year world water view using urbanization urban...  \n",
      "327  verde united uneca ratio rate primary nations ...  \n",
      "..                                                 ...  \n",
      "512  uganda therefore society service schools schoo...  \n",
      "126  world women wider various unesco today ties su...  \n",
      "413  year world water view using urbanization urban...  \n",
      "4    website university types theme team schools sc...  \n",
      "356  year world water view using urbanization urban...  \n",
      "\n",
      "[100 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#create testing data set\n",
    "\n",
    "evaluation_set = df.sample(100)\n",
    "\n",
    "print(evaluation_set)\n",
    "\n",
    "#evaluation_set = pd.read_csv('good_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water points - water sources', 0.5745146),\n",
       " ('water sanitation and hygiene - wash', 0.53523254),\n",
       " ('water bodies - hydrography', 0.5220669),\n",
       " ('people targeted for assistance', 0.51016665),\n",
       " ('access to water', 0.5070385),\n",
       " ('hazardous areas', 0.5036735),\n",
       " ('social development centers', 0.50205225),\n",
       " ('host communities', 0.49804816),\n",
       " ('people in need - pin', 0.49558908),\n",
       " ('cultural sites', 0.4949108)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of cosine distance\n",
    "Utility.cosine_distance(df['tfidf'].ix[20], tag_list_clean,model,index2word_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code snippets- for each dataset:\n",
    " 1) get the document that we want to extract keywords from\n",
    " 2) generate tf-idf for the document\n",
    " 3) sort the tf-idf vectors by descending order of scores\n",
    " 4) extract only the top ; n here is 20 (Num_of_words)\n",
    " 5) clean the content (number, special character,links and/or non-english chars removal )\n",
    " 6) concatenate the text content from all metdata fields.\n",
    "'''\n",
    "evaluation_set['tfidf'] =\"\"\n",
    "for i, row in evaluation_set.iterrows():\n",
    "    doc=evaluation_set.ix[i]['All_text']\n",
    "    candidates=\"\"\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc])) #tfidf_transformer.transform(\n",
    "    sorted_items=Utility.sort_coo(tf_idf_vector.tocoo()) \n",
    "    keywords=Utility.extract_topn_from_vector(feature_names,sorted_items,Num_of_words)\n",
    "    for k in keywords:\n",
    "        candidates+=k +\" \"\n",
    "    evaluation_set.at[i,'tfidf'] = candidates      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('affected population', 0.5433383),\n",
       " ('people targeted for assistance', 0.50946397),\n",
       " ('access to education', 0.49615312),\n",
       " ('vulnerable populations', 0.49022922),\n",
       " ('population movement', 0.4862483),\n",
       " ('education facilities - schools', 0.48593074),\n",
       " ('persons of concern - populations of concern - poc', 0.48053625),\n",
       " ('people in need - pin', 0.47038212),\n",
       " ('mine risk education', 0.4692416),\n",
       " ('social development centers', 0.4653482)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of cosine distance\n",
    "Utility.cosine_distance(evaluation_set['tfidf'].iloc[0], tag_list_clean,model,index2word_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'perfect_tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'perfect_tags'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8d0a25b32417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#problem for reading list from CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mast\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'perfect_tags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'perfect_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'perfect_tags'"
     ]
    }
   ],
   "source": [
    "## convert the string of list (tags) to list of (tags) \n",
    "#problem for reading list from CSV\n",
    "from ast import literal_eval\n",
    "evaluation_set.loc[:,'perfect_tags'] = evaluation_set.loc[:,'perfect_tags'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('governance and civil society', 0.52650523),\n",
       " ('social development centers', 0.52534616),\n",
       " ('sustainable development', 0.5186519),\n",
       " ('educational attainment', 0.49680942),\n",
       " ('education cluster', 0.46917826),\n",
       " ('health services - healthcare', 0.4673657),\n",
       " ('sustainable development goals - sdg', 0.46731296),\n",
       " ('reproductive health and family planning', 0.4597844),\n",
       " ('host communities', 0.45850664),\n",
       " ('religious facilities', 0.45708698)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of cosine distance\n",
    "Utility.cosine_distance(evaluation_set['tfidf'].ix[98], tag_list_clean,model,index2word_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rec'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3f27fc21afaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# perfect_list: list of valid tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mactual_flist\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tag_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred_list\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtfidf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtf_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hdxtag3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rec'"
     ]
    }
   ],
   "source": [
    "# Actual list: is the list of tags currenly assigned to the dataset by the providers.\n",
    "# pred_list: The list of tags suggested by the model.\n",
    "#tfidf_list: list of keywords extracted by tfidf\n",
    "# tf_listL list of keywords extracted by term frequncy\n",
    "# perfect_list: list of valid tags.\n",
    "actual_flist= evaluation_set['tag_list']\n",
    "pred_list= evaluation_set['rec']\n",
    "tfidf_list = evaluation_set['tfidf']\n",
    "tf_list = evaluation_set['tf']\n",
    "perfect_list = evaluation_set['perfect_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare top words with the perfect list:\n",
    "# an idea to overcome the exact matching.\n",
    "result_tfidf=[]\n",
    "for document_lst, pred_tags in zip(perfect_list,tfidf_list):\n",
    "    matching= [s for s in document_lst if any(s in xs or xs in s for xs in [pred_tags])]\n",
    "    result_tfidf.append((len(matching), len(document_lst)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compuate the recall for the keywords. \n",
    "\n",
    "tfidf_recall = []\n",
    "for t in result_tfidf:\n",
    "    tfidf_recall.append(t[0]/t[1])\n",
    "np.average(tfidf_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional - tag cleaning\n",
    "P_tags =  Utility.clean_tag(new_tag_list_clean)\n",
    "good_tags = Utility.remove_stopwords(pd.Series(P_tags), stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of cosine distance\n",
    "Utility.cosine_distance(\"secondary data secondary nigeria data sdr review sdr review nigeria education education secondary data review sdr secondary sdr nigeria matrix nigeria matrix education nigeria education education data matrix\", tag_list_clean,model,index2word_set,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the evaluation set \n",
    "# represent the tfidf of the documents into word2vec. \n",
    "# Find top tags from the clean_list to each dataset using the \n",
    "df['rec'] = \"\"\n",
    "for i, row in df.iterrows():\n",
    "    doc = df.ix[i]['tfidf']\n",
    "    #if i ==12:\n",
    "     #   print(doc)\n",
    "    suggested_tags =Utility.cosine_distance_list(doc, tag_list_clean,model,index2word_set,5 )#evaluation_set.ix[i]['k']+5) \n",
    "    #print(suggested_tags)\n",
    "    df.at[i, 'rec'] = suggested_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##final list\n",
    "## represent the tfidf of the documents into word2vec\n",
    "##recommend tags from the hdx valid tag list to each dataset based on cosine distance \n",
    "for i, row in evaluation_set.iterrows():\n",
    "    doc = evaluation_set.ix[i]['tfidf']\n",
    "    suggested_tags =Utility.cosine_distance_list(doc, good_tags,model,index2word_set,evaluation_set.ix[i]['k']+5)\n",
    "    #print(suggested_tags)\n",
    "    evaluation_set.at[i, 'rec'] = suggested_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list= evaluation_set['rec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####compare word2vec of top words with the perfect list:\n",
    "## an idea for the comparsion\n",
    "res_word2vec=[]\n",
    "total = 0\n",
    "for document_lst, pred_tags in zip(perfect_list,pred_list):\n",
    "    matching= [s for s in document_lst if any(s in xs or xs in s for xs in pred_tags)]\n",
    "    print(\"document_lst\", document_lst)\n",
    "    print(\"predicted\", pred_list)\n",
    "    res_word2vec.append((len(matching), len(document_lst)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_recall = []\n",
    "for t in res_word2vec:\n",
    "    word2vec_recall.append(t[0]/t[1])\n",
    "print(np.mean(word2vec_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
